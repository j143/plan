{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ab83f4",
   "metadata": {},
   "source": [
    "# Basic Simulation Workflow\n",
    "\n",
    "This notebook demonstrates how to set up a basic simulation of distributed deep learning training using the Distributed Training Simulator. We'll cover:\n",
    "\n",
    "1. Setting up communication, compute, and memory models\n",
    "2. Configuring the simulation parameters\n",
    "3. Running a simulation and analyzing results\n",
    "4. Visualizing the simulation outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97058d9e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca56106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dist_training_sim as dts\n",
    "from dist_training_sim.visualization import Visualizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ed8c7",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "The distributed training simulator consists of three core models:\n",
    "\n",
    "1. **Communication Model**: Simulates the network topology and communication patterns\n",
    "2. **Compute Model**: Simulates computational resources and operations\n",
    "3. **Memory Model**: Simulates memory systems and data movement\n",
    "\n",
    "Let's create instances of each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a communication model with 8 nodes in a ring topology\n",
    "comm_model = dts.CommunicationModel(num_nodes=8, topology=dts.Topology.RING)\n",
    "\n",
    "# Create a compute model with 8 GPU devices\n",
    "compute_model = dts.ComputeModel(num_devices=8, device_type=dts.DeviceType.GPU)\n",
    "\n",
    "# Create a memory model with 8 devices\n",
    "memory_model = dts.MemoryModel(num_devices=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ef959",
   "metadata": {},
   "source": [
    "## Configuring the Communication Model\n",
    "\n",
    "Let's customize our communication model to have different link properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b476d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define high-speed links for our ring\n",
    "high_speed_links = dts.LinkProperties()\n",
    "high_speed_links.bandwidth_gbps = 100.0  # 100 Gbps\n",
    "high_speed_links.latency_us = 5.0        # 5 microseconds\n",
    "high_speed_links.error_rate = 0.0\n",
    "\n",
    "# Set uniform link properties across all connections\n",
    "comm_model.setUniformLinkProperties(high_speed_links)\n",
    "\n",
    "# Simulate a point-to-point transfer of 100MB\n",
    "transfer_time_ms = comm_model.simulateSendRecv(0, 1, 100 * 1024 * 1024)\n",
    "print(f\"Time to transfer 100MB between nodes 0 and 1: {transfer_time_ms:.2f} ms\")\n",
    "\n",
    "# Simulate a collective operation (all-reduce) with 100MB per node\n",
    "allreduce_time_ms = comm_model.simulateAllReduce(100 * 1024 * 1024)\n",
    "print(f\"Time to perform all-reduce with 100MB per node: {allreduce_time_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ded52b",
   "metadata": {},
   "source": [
    "## Configuring the Compute Model\n",
    "\n",
    "Now let's customize our compute model with specific device properties and workload characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom GPU properties (based on high-end GPU)\n",
    "gpu_props = dts.DeviceProperties()\n",
    "gpu_props.flops = 15.0e12         # 15 TFLOPS\n",
    "gpu_props.memory_bandwidth = 900.0 # 900 GB/s\n",
    "gpu_props.memory_size = 32768      # 32 GB\n",
    "gpu_props.cores = 108              # 108 SMs\n",
    "\n",
    "# Set uniform device properties\n",
    "compute_model.setUniformDeviceProperties(gpu_props)\n",
    "\n",
    "# Configure batch size and model size\n",
    "compute_model.setBatchSize(256)\n",
    "compute_model.setModelSize(parameters=300e6, activations=150e6)  # 300M params, 150M activations\n",
    "\n",
    "# Simulate a forward pass on device 0\n",
    "forward_time_ms = compute_model.simulateOperation(dts.Operation.FORWARD_PASS, 0)\n",
    "print(f\"Forward pass time on device 0: {forward_time_ms:.2f} ms\")\n",
    "\n",
    "# Simulate a backward pass on device 0\n",
    "backward_time_ms = compute_model.simulateOperation(dts.Operation.BACKWARD_PASS, 0)\n",
    "print(f\"Backward pass time on device 0: {backward_time_ms:.2f} ms\")\n",
    "\n",
    "# Simulate a full training iteration\n",
    "iteration_time_ms = compute_model.simulateFullTrainingIteration(0)\n",
    "print(f\"Full training iteration time on device 0: {iteration_time_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74587388",
   "metadata": {},
   "source": [
    "## Configuring the Memory Model\n",
    "\n",
    "Let's customize our memory model to reflect a specific hardware configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom high-bandwidth memory tier\n",
    "hbm_tier = dts.MemoryTier()\n",
    "hbm_tier.type = dts.MemoryType.HBM\n",
    "hbm_tier.capacity_bytes = 32 * 1024 * 1024 * 1024  # 32 GB\n",
    "hbm_tier.bandwidth_gbps = 1200.0                   # 1.2 TB/s\n",
    "hbm_tier.latency_ns = 100.0                        # 100 ns\n",
    "\n",
    "# Add this memory tier to device 0\n",
    "memory_model.addMemoryTier(0, hbm_tier)\n",
    "\n",
    "# Simulate allocating 10 GB on device 0's HBM\n",
    "allocation_time_ms = memory_model.simulateAllocation(0, dts.MemoryType.HBM, 10 * 1024 * 1024 * 1024)\n",
    "print(f\"Time to allocate 10GB on device 0's HBM: {allocation_time_ms:.2f} ms\")\n",
    "\n",
    "# Simulate transferring 5 GB from device 0's HBM to device 0's CPU RAM\n",
    "transfer_time_ms = memory_model.simulateTransfer(\n",
    "    0, dts.MemoryType.HBM, \n",
    "    0, dts.MemoryType.CPU_RAM, \n",
    "    5 * 1024 * 1024 * 1024\n",
    ")\n",
    "print(f\"Time to transfer 5GB from HBM to CPU RAM: {transfer_time_ms:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e95fe",
   "metadata": {},
   "source": [
    "## Creating a Simulator\n",
    "\n",
    "Now, let's combine these models to create a complete training simulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23c385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the simulator with our models\n",
    "simulator = dts.TrainingSimulator(comm_model, compute_model, memory_model)\n",
    "\n",
    "# Configure the simulator\n",
    "simulator.setBatchSize(256)\n",
    "simulator.setModelSize(parameters=300e6, activations=150e6)\n",
    "simulator.setParallelStrategy(dts.ParallelStrategy.DATA_PARALLEL)\n",
    "simulator.setOptimizer(dts.OptimizerType.ADAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad75fb7",
   "metadata": {},
   "source": [
    "## Running the Simulation\n",
    "\n",
    "Let's run a simulation of a training iteration and examine the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the simulation\n",
    "results = simulator.simulateTrainingIteration()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Total iteration time: {results.total_time_ms:.2f} ms\")\n",
    "print(f\"Compute time: {results.compute_time_ms:.2f} ms\")\n",
    "print(f\"Communication time: {results.communication_time_ms:.2f} ms\")\n",
    "print(f\"Memory operation time: {results.memory_time_ms:.2f} ms\")\n",
    "print(f\"Compute efficiency: {results.compute_efficiency:.2f}%\")\n",
    "print(f\"Communication efficiency: {results.communication_efficiency:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78214dfb",
   "metadata": {},
   "source": [
    "## Visualizing the Results\n",
    "\n",
    "Let's visualize the simulation results using the visualization module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8947383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a visualizer\n",
    "vis = Visualizer()\n",
    "\n",
    "# Plot the training timeline\n",
    "fig = vis.plot_training_timeline(results.events)\n",
    "plt.show()\n",
    "\n",
    "# Plot the communication graph\n",
    "fig = vis.plot_communication_graph(results.comm_adjacency)\n",
    "plt.show()\n",
    "\n",
    "# Plot memory usage by device\n",
    "memory_data = {\n",
    "    \"GPU VRAM\": results.memory_usage_by_device,\n",
    "    \"CPU RAM\": results.host_memory_usage_by_device\n",
    "}\n",
    "fig = vis.plot_memory_usage(range(8), memory_data, results.memory_capacity_by_device)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bb85d",
   "metadata": {},
   "source": [
    "## Scaling Simulation\n",
    "\n",
    "Let's simulate how the system scales across different numbers of devices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bed72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a range of device counts to test\n",
    "device_counts = [1, 2, 4, 8, 16, 32]\n",
    "throughputs = []\n",
    "efficiencies = []\n",
    "\n",
    "# Base throughput for efficiency calculation\n",
    "base_samples_per_sec = None\n",
    "\n",
    "for count in device_counts:\n",
    "    # Create models with the specified device count\n",
    "    temp_comm_model = dts.CommunicationModel(num_nodes=count, topology=dts.Topology.RING)\n",
    "    temp_compute_model = dts.ComputeModel(num_devices=count, device_type=dts.DeviceType.GPU)\n",
    "    temp_memory_model = dts.MemoryModel(num_devices=count)\n",
    "    \n",
    "    # Configure models\n",
    "    temp_comm_model.setUniformLinkProperties(high_speed_links)\n",
    "    temp_compute_model.setUniformDeviceProperties(gpu_props)\n",
    "    temp_compute_model.setBatchSize(256 * count)  # Scale batch size with device count\n",
    "    temp_compute_model.setModelSize(parameters=300e6, activations=150e6)\n",
    "    \n",
    "    # Create simulator\n",
    "    temp_simulator = dts.TrainingSimulator(temp_comm_model, temp_compute_model, temp_memory_model)\n",
    "    temp_simulator.setBatchSize(256 * count)\n",
    "    temp_simulator.setModelSize(parameters=300e6, activations=150e6)\n",
    "    temp_simulator.setParallelStrategy(dts.ParallelStrategy.DATA_PARALLEL)\n",
    "    \n",
    "    # Run simulation\n",
    "    temp_results = temp_simulator.simulateTrainingIteration()\n",
    "    \n",
    "    # Calculate throughput (samples/sec)\n",
    "    samples_per_sec = (256 * count) / (temp_results.total_time_ms / 1000)\n",
    "    throughputs.append(samples_per_sec)\n",
    "    \n",
    "    # Calculate efficiency\n",
    "    if base_samples_per_sec is None:\n",
    "        base_samples_per_sec = samples_per_sec\n",
    "        efficiencies.append(100.0)\n",
    "    else:\n",
    "        ideal_throughput = base_samples_per_sec * count\n",
    "        efficiency = 100 * samples_per_sec / ideal_throughput\n",
    "        efficiencies.append(efficiency)\n",
    "    \n",
    "    print(f\"{count} devices: {samples_per_sec:.2f} samples/sec, {efficiencies[-1]:.2f}% efficiency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b28006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaling results\n",
    "fig = vis.plot_scaling_efficiency(device_counts, throughputs, efficiencies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5841f5d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the basic workflow for using the Distributed Training Simulator:\n",
    "\n",
    "1. Creating and configuring the three core models (communication, compute, and memory)\n",
    "2. Setting up a simulation environment\n",
    "3. Running simulations and analyzing results\n",
    "4. Visualizing the outcomes of simulations\n",
    "5. Investigating scaling performance\n",
    "\n",
    "This provides a foundation for more advanced simulations and analyses of distributed training systems."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
